import {
  QWEN3_0_6B_QUANTIZED,
  QWEN3_0_6B,
  QWEN3_1_7B,
  QWEN3_1_7B_QUANTIZED,
  QWEN3_4B,
  QWEN3_4B_QUANTIZED,
  LLAMA3_2_1B,
  LLAMA3_2_1B_QLORA,
  LLAMA3_2_1B_SPINQUANT,
  LLAMA3_2_3B,
  LLAMA3_2_3B_QLORA,
  LLAMA3_2_3B_SPINQUANT,
  HAMMER2_1_0_5B,
  HAMMER2_1_0_5B_QUANTIZED,
  HAMMER2_1_1_5B,
  HAMMER2_1_1_5B_QUANTIZED,
  HAMMER2_1_3B,
  HAMMER2_1_3B_QUANTIZED,
  QWEN2_5_0_5B,
  QWEN2_5_0_5B_QUANTIZED,
  QWEN2_5_1_5B,
  QWEN2_5_1_5B_QUANTIZED,
  QWEN2_5_3B,
  QWEN2_5_3B_QUANTIZED,
  PHI_4_MINI_4B,
  PHI_4_MINI_4B_QUANTIZED,
} from 'react-native-executorch';

export const startingModels = [
  'LLaMA 3.2 - 1B - SpinQuant',
  'Qwen 3 - 0.6B - Quantized',
  'Qwen 3 - 1.7B - Quantized',
];

export const DEFAULT_MODELS = [
  {
    modelName: 'Qwen 3 - 0.6B - Quantized',
    modelPath: QWEN3_0_6B_QUANTIZED.modelSource,
    tokenizerPath: QWEN3_0_6B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: QWEN3_0_6B_QUANTIZED.tokenizerConfigSource,
    parameters: 0.75,
    modelSize: 0.94,
    featured: true,
    thinking: true,
    labels: ['Fast', 'Quantized', 'Reasoning'],
  },
  {
    modelName: 'Qwen 3 - 0.6B',
    modelPath: QWEN3_0_6B.modelSource,
    tokenizerPath: QWEN3_0_6B.tokenizerSource,
    tokenizerConfigPath: QWEN3_0_6B.tokenizerConfigSource,
    parameters: 0.75,
    modelSize: 1.19,
    featured: true,
    thinking: true,
    labels: ['Balanced', 'Reasoning'],
  },
  {
    modelName: 'Qwen 3 - 1.7B',
    modelPath: QWEN3_1_7B.modelSource,
    tokenizerPath: QWEN3_1_7B.tokenizerSource,
    tokenizerConfigPath: QWEN3_1_7B.tokenizerConfigSource,
    parameters: 2.03,
    modelSize: 3.44,
    featured: true,
    thinking: true,
    labels: ['Smart', 'Reasoning'],
  },
  {
    modelName: 'Qwen 3 - 1.7B - Quantized',
    modelPath: QWEN3_1_7B_QUANTIZED.modelSource,
    tokenizerPath: QWEN3_1_7B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: QWEN3_1_7B_QUANTIZED.tokenizerConfigSource,
    parameters: 2.03,
    modelSize: 2.16,
    featured: true,
    thinking: true,
    labels: ['Smart', 'Quantized', 'Reasoning'],
  },
  {
    modelName: 'Qwen 3 - 4B',
    modelPath: QWEN3_4B.modelSource,
    tokenizerPath: QWEN3_4B.tokenizerSource,
    tokenizerConfigPath: QWEN3_4B.tokenizerConfigSource,
    parameters: 4.02,
    modelSize: 8.05,
    thinking: true,
    labels: ['Smart', 'Reasoning'],
  },
  {
    modelName: 'Qwen 3 - 4B - Quantized',
    modelPath: QWEN3_4B_QUANTIZED.modelSource,
    tokenizerPath: QWEN3_4B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: QWEN3_4B_QUANTIZED.tokenizerConfigSource,
    parameters: 4.02,
    modelSize: 3.7,
    thinking: true,
    labels: ['Smart', 'Quantized', 'Reasoning'],
  },
  {
    modelName: 'LLaMA 3.2 - 1B',
    modelPath: LLAMA3_2_1B.modelSource,
    tokenizerPath: LLAMA3_2_1B.tokenizerSource,
    tokenizerConfigPath: LLAMA3_2_1B.tokenizerConfigSource,
    parameters: 1.24,
    modelSize: 2.47,
    featured: true,
    labels: ['Balanced'],
  },
  {
    modelName: 'LLaMA 3.2 - 1B - QLoRa',
    modelPath: LLAMA3_2_1B_QLORA.modelSource,
    tokenizerPath: LLAMA3_2_1B_QLORA.tokenizerSource,
    tokenizerConfigPath: LLAMA3_2_1B_QLORA.tokenizerConfigSource,
    parameters: 1.24,
    modelSize: 1.18,
    featured: true,
    labels: ['Good at coding', 'Quantized'],
  },
  {
    modelName: 'LLaMA 3.2 - 1B - SpinQuant',
    modelPath: LLAMA3_2_1B_SPINQUANT.modelSource,
    tokenizerPath: LLAMA3_2_1B_SPINQUANT.tokenizerSource,
    tokenizerConfigPath: LLAMA3_2_1B_SPINQUANT.tokenizerConfigSource,
    parameters: 1.24,
    modelSize: 1.14,
    featured: true,
    labels: ['Good at coding', 'Fast', 'Great first model', 'Quantized'],
  },
  {
    modelName: 'LLaMA 3.2 - 3B',
    modelPath: LLAMA3_2_3B.modelSource,
    tokenizerPath: LLAMA3_2_3B.tokenizerSource,
    tokenizerConfigPath: LLAMA3_2_3B.tokenizerConfigSource,
    parameters: 3.21,
    modelSize: 6.43,
    labels: ['Good at coding'],
  },
  {
    modelName: 'LLaMA 3.2 - 3B - QLoRa',
    modelPath: LLAMA3_2_3B_QLORA.modelSource,
    tokenizerPath: LLAMA3_2_3B_QLORA.tokenizerSource,
    tokenizerConfigPath: LLAMA3_2_3B_QLORA.tokenizerConfigSource,
    parameters: 3.21,
    modelSize: 2.65,
    labels: ['Good at coding', 'Quantized'],
  },
  {
    modelName: 'LLaMA 3.2 - 3B - SpinQuant',
    modelPath: LLAMA3_2_3B_SPINQUANT.modelSource,
    tokenizerPath: LLAMA3_2_3B_SPINQUANT.tokenizerSource,
    tokenizerConfigPath: LLAMA3_2_3B_SPINQUANT.tokenizerConfigSource,
    parameters: 3.21,
    modelSize: 2.55,
    labels: ['Good at coding', 'Fast', 'Quantized'],
  },
  {
    modelName: 'Hammer 2.1 - 0.5B',
    modelPath: HAMMER2_1_0_5B.modelSource,
    tokenizerPath: HAMMER2_1_0_5B.tokenizerSource,
    tokenizerConfigPath: HAMMER2_1_0_5B.tokenizerConfigSource,
    parameters: 0.49,
    modelSize: 0.99,
    labels: ['Fast', 'Function calling'],
  },
  {
    modelName: 'Hammer 2.1 - 0.5B - Quantized',
    modelPath: HAMMER2_1_0_5B_QUANTIZED.modelSource,
    tokenizerPath: HAMMER2_1_0_5B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: HAMMER2_1_0_5B_QUANTIZED.tokenizerConfigSource,
    parameters: 0.49,
    modelSize: 0.81,
    labels: ['Fast', 'Function calling', 'Quantized'],
  },
  {
    modelName: 'Hammer 2.1 - 1.5B',
    modelPath: HAMMER2_1_1_5B.modelSource,
    tokenizerPath: HAMMER2_1_1_5B.tokenizerSource,
    tokenizerConfigPath: HAMMER2_1_1_5B.tokenizerConfigSource,
    parameters: 1.54,
    modelSize: 3.09,
    labels: ['Balanced', 'Function calling'],
  },
  {
    modelName: 'Hammer 2.1 - 1.5B - Quantized',
    modelPath: HAMMER2_1_1_5B_QUANTIZED.modelSource,
    tokenizerPath: HAMMER2_1_1_5B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: HAMMER2_1_1_5B_QUANTIZED.tokenizerConfigSource,
    parameters: 1.54,
    modelSize: 1.76,
    labels: ['Balanced', 'Function calling', 'Quantized'],
  },
  {
    modelName: 'Hammer 2.1 - 3B',
    modelPath: HAMMER2_1_3B.modelSource,
    tokenizerPath: HAMMER2_1_3B.tokenizerSource,
    tokenizerConfigPath: HAMMER2_1_3B.tokenizerConfigSource,
    parameters: 3.09,
    modelSize: 6.17,
    labels: ['Powerful', 'Function calling'],
  },
  {
    modelName: 'Hammer 2.1 - 3B - Quantized',
    modelPath: HAMMER2_1_3B_QUANTIZED.modelSource,
    tokenizerPath: HAMMER2_1_3B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: HAMMER2_1_3B_QUANTIZED.tokenizerConfigSource,
    parameters: 3.09,
    modelSize: 2.89,
    labels: ['Powerful', 'Function calling', 'Quantized'],
  },
  {
    modelName: 'Qwen 2.5 - 0.5B',
    modelPath: QWEN2_5_0_5B.modelSource,
    tokenizerPath: QWEN2_5_0_5B.tokenizerSource,
    tokenizerConfigPath: QWEN2_5_0_5B.tokenizerConfigSource,
    parameters: 0.49,
    modelSize: 0.99,
    labels: ['Fast', 'Small'],
  },
  {
    modelName: 'Qwen 2.5 - 0.5B - Quantized',
    modelPath: QWEN2_5_0_5B_QUANTIZED.modelSource,
    tokenizerPath: QWEN2_5_0_5B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: QWEN2_5_0_5B_QUANTIZED.tokenizerConfigSource,
    parameters: 0.49,
    modelSize: 0.81,
    labels: ['Fast', 'Small'],
  },
  {
    modelName: 'Qwen 2.5 - 1.5B',
    modelPath: QWEN2_5_1_5B.modelSource,
    tokenizerPath: QWEN2_5_1_5B.tokenizerSource,
    tokenizerConfigPath: QWEN2_5_1_5B.tokenizerConfigSource,
    parameters: 1.54,
    modelSize: 3.09,
    labels: ['Balanced'],
  },
  {
    modelName: 'Qwen 2.5 - 1.5B - Quantized',
    modelPath: QWEN2_5_1_5B_QUANTIZED.modelSource,
    tokenizerPath: QWEN2_5_1_5B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: QWEN2_5_1_5B_QUANTIZED.tokenizerConfigSource,
    parameters: 1.54,
    modelSize: 1.76,
    labels: ['Balanced', 'Quantized'],
  },
  {
    modelName: 'Qwen 2.5 - 3B',
    modelPath: QWEN2_5_3B.modelSource,
    tokenizerPath: QWEN2_5_3B.tokenizerSource,
    tokenizerConfigPath: QWEN2_5_3B.tokenizerConfigSource,
    parameters: 3.09,
    modelSize: 6.17,
    labels: ['Powerful'],
  },
  {
    modelName: 'Qwen 2.5 - 3B - Quantized',
    modelPath: QWEN2_5_3B_QUANTIZED.modelSource,
    tokenizerPath: QWEN2_5_3B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: QWEN2_5_3B_QUANTIZED.tokenizerConfigSource,
    parameters: 3.09,
    modelSize: 2.89,
    labels: ['Powerful', 'Quantized'],
  },
  {
    modelName: 'PHI 4 MINI',
    modelPath: PHI_4_MINI_4B.modelSource,
    tokenizerPath: PHI_4_MINI_4B.tokenizerSource,
    tokenizerConfigPath: PHI_4_MINI_4B.tokenizerConfigSource,
    parameters: 3.84,
    modelSize: 7.67,
    labels: ['Good at coding', 'Smart'],
  },
  {
    modelName: 'PHI 4 MINI - Quantized',
    modelPath: PHI_4_MINI_4B_QUANTIZED.modelSource,
    tokenizerPath: PHI_4_MINI_4B_QUANTIZED.tokenizerSource,
    tokenizerConfigPath: PHI_4_MINI_4B_QUANTIZED.tokenizerConfigSource,
    parameters: 3.84,
    modelSize: 4.5,
    labels: ['Good at coding', 'Quantized'],
  },
];
